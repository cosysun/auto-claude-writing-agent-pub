# Design: Improve Topic Research and Tool Usage

**Date**: 2026-01-21
**Status**: Draft

---

## Overview

本次设计旨在解决两个核心问题：
1. 选题热度评估不准确（使用海外媒体导致与国内受众脱节）
2. 工具使用不明确（WebFetch vs WebSearch）

---

## Design Decisions

### Decision 1: 在Step 2和Step 3之间插入新步骤（Step 2.5）

**选项A**：修改Step 2，在信息搜索中加入热度评估
- ❌ 会让Step 2变得冗长复杂
- ❌ 混淆"技术调研"和"热度评估"两个不同目标

**选项B**：修改Step 3，在选题讨论时要求热度依据
- ❌ 太晚了，已经进入选题阶段
- ❌ 无法指导如何获取热度信息

**选项C（选择）**：新增Step 2.5专门处理热度评估
- ✅ 职责单一，逻辑清晰
- ✅ 在选题讨论前完成热度验证
- ✅ 不影响原有流程
- ✅ 可选步骤，灵活性高

**理由**：
- 热度评估是独立的工作，需要专门的信息源和方法
- 放在Step 2（技术调研）和Step 3（选题讨论）之间最合理
- 符合"渐进增强"原则，不破坏现有流程

---

### Decision 2: 本地化热度评估的三要素

**核心设计**：
1. **社交媒体热度**（数据层）
2. **同行选题**（行业层）
3. **用户反馈**（需求层）

**为什么是这三个？**

**社交媒体热度**：
- 反映大众关注度
- 数据相对客观
- 可量化（热搜排名、指数）
- **风险**：可能被限制访问
- **缓解**：提供替代信息源（少数派、机器之心）

**同行选题**：
- 反映行业趋势
- 已验证的选题方向
- 可参考写作角度
- **风险**：可能同质化
- **缓解**：强调差异化角度

**用户反馈**：
- 反映真实需求
- 最直接的信号
- 高度相关
- **风险**：样本可能有限
- **缓解**：结合其他两个维度

**为什么不是单一维度？**
- 单一维度容易偏差
- 三个维度互相验证，更可靠
- 覆盖"热度-趋势-需求"完整链条

---

### Decision 3: WebFetch优先原则

**设计原则**：优先使用WebFetch，特定情况使用WebSearch

**理由**：

**WebFetch的优势**：
- 获取特定网站的完整内容
- 更适合中文平台（少数派、机器之心）
- 用户可控（明确知道抓取哪个网站）
- 结果更聚焦

**WebSearch的适用场景**：
- 不确定信息源在哪
- 需要多个来源综合
- 概念性快速调研

**实现方式**：
- 在Step 2明确写出优先级
- 提供具体使用示例
- 说明判断标准

**风险和缓解**：
- **风险**：WebFetch可能遇到登录限制
- **缓解**：提供多个替代信息源
- **风险**：用户可能不理解区别
- **缓解**：提供清晰的对比表格和示例

---

### Decision 4: 信息源分类设计

**分类维度**：

**1. 按内容类型**：
- 社交媒体：微博、知乎、小红书
- 科技资讯：少数派、机器之心、36氪、虎嗅
- 技术社区：Hacker News、V2EX、掘金
- 官方来源：官方博客、文档

**2. 按访问难度**：
- ✅ 公开可访问：少数派、机器之心
- ⚠️ 需要登录：微博、知乎
- ❌ 国内受限：TechCrunch、The Verge

**3. 按用途**：
- 热度评估：社交媒体、科技资讯
- 技术调研：官方文档、技术社区
- 同行参考：科技资讯、同类公众号

**设计成文档**：
- 创建 `_writing_reference/china-info-sources.md`
- 按分类整理
- 标注访问难度和用途
- 提供WebFetch使用示例

---

### Decision 5: 选题模板增强

**当前模板**：
```markdown
### 选题X：[标题]
**核心角度**：...
**工作量评估**：...
**优势**：...
**劣势**：...
```

**新增字段**：
```markdown
### 选题X：[标题]

**热度依据**：⭐⭐⭐⭐⭐（新增）
- 社交媒体：[具体数据/观察]
- 同行选题：[参考案例]
- 用户需求：[反馈来源]

**核心角度**：...
（其他保持不变）
```

**为什么这样设计？**
- 强制AI提供热度证据
- 用户可以快速判断热度真实性
- 三个子项对应三要素
- 星级评价直观

---

## Technical Approach

### 热度评估流程（Step 2.5）

```
1. 【Think Aloud】说明热度评估目标
   ↓
2. 使用WebFetch获取中文平台热门话题
   - 少数派首页
   - 机器之心最新文章
   - （可选）其他可访问平台
   ↓
3. 提取AI相关热点关键词
   - 标注来源
   - 标注热度指标（如果有）
   ↓
4. 结合频道定位筛选
   - 是否符合"AI技术拆解师"定位？
   - 是否符合"提效"主题？
   - 目标受众是否关心？
   ↓
5. 输出热点清单
   - 3-5个热点方向
   - 每个附带热度依据
   ↓
6. 进入Step 3（选题讨论）
```

### 工具选择决策树

```
需要获取信息
    ↓
是否知道具体网站？
    ├── 是 → 使用WebFetch
    │       ├── 国内平台（少数派、机器之心）
    │       ├── 官方文档
    │       └── 特定搜索结果页
    │
    └── 否 → 使用WebSearch
            ├── 不确定信息源
            ├── 需要多源综合
            └── 概念性快速调研
```

---

## Data Model

### 热度评估记录格式

```markdown
## 热度评估记录

**评估时间**：YYYY-MM-DD HH:MM
**评估目标**：[本次brief的主题]

### 社交媒体热度
- 平台：[微博/知乎/其他]
- 关键词：[搜索的关键词]
- 热度指标：[热搜排名/讨论量/等]
- 观察：[具体发现]

### 同行选题
- 信息源：[少数派/机器之心/其他]
- 热门文章：[标题列表]
- 趋势分析：[观察到的趋势]

### 用户需求
- 来源：[评论区/社群/私信]
- 高频问题：[列表]
- 需求分析：[总结]

### 筛选结果
- 热点1：[名称]（热度：⭐⭐⭐⭐⭐）
- 热点2：[名称]（热度：⭐⭐⭐⭐）
- 热点3：[名称]（热度：⭐⭐⭐）
```

---

## Integration Points

### 与现有流程的集成

**Step 1（理解需求）**：
- 不变，保持原有流程

**Step 2（信息搜索）**：
- 增加工具使用规范（WebFetch优先）
- 明确"技术调研"的目标
- 保持原有的知识库保存流程

**Step 2.5（热度评估）**：⭐ **新增**
- 使用WebFetch获取中文平台热度
- 结合频道定位筛选
- 输出热点清单

**Step 3（选题讨论）**：
- 选题模板增加"热度依据"字段
- 要求基于Step 2.5的热点清单
- 其他保持不变

**Step 4-10**：
- 不变，保持原有流程

---

## Error Handling

### 场景1：中文平台无法访问

**处理方式**：
- 尝试替代信息源（少数派、机器之心）
- 如果全部失败，使用WebSearch搜索中文资讯
- 实在不行，询问用户近期观察到的热点

### 场景2：热度信息不足

**处理方式**：
- 说明当前信息有限
- 提供基于有限信息的判断
- 标注"热度待验证"
- 建议用户补充观察

### 场景3：与brief主题冲突

**处理方式**：
- 优先尊重brief的主题
- 热度评估仅作为参考
- 如果热度差距很大，提醒用户

---

## Performance Considerations

### 步骤耗时

- Step 2.5预计耗时：5-10分钟
- 主要耗时：WebFetch请求（2-3个网站）
- 分析和筛选：2-3分钟

### 优化策略

- 并行WebFetch请求（同时抓取多个网站）
- 缓存常用信息源的结果（15分钟）
- 提供快速模式（只查1-2个源）

---

## Security and Privacy

### 数据安全

- 不存储用户的社交媒体账号信息
- WebFetch只获取公开内容
- 热度评估记录可选保存

### 隐私保护

- 不要求用户提供私密信息
- 用户反馈匿名化处理
- 评论区分析不涉及个人隐私

---

## Testing Strategy

### 单元测试

- WebFetch工具选择逻辑
- 热度评估筛选逻辑
- 选题模板格式验证

### 集成测试

- 完整的Step 2 → 2.5 → 3流程
- 不同类型brief的热度评估
- 工具使用正确性

### 用户测试

- 用户对选题热度的认可度
- 工具使用无需纠正次数
- 整体流程满意度

---

## Rollout Plan

### Phase 1: 文档更新（本次）
- 更新CLAUDE.md
- 创建信息源清单
- 添加示例

### Phase 2: 验证测试
- 用实际场景测试新流程
- 收集反馈
- 微调

### Phase 3: 持续优化
- 根据使用情况更新信息源
- 补充更多示例
- 优化热度评估标准

---

## Appendix

### 参考案例

**改进前**：
- 推荐Mastra、Agent Skills Leaderboard（极小众）
- 基于TechCrunch、Hacker News
- 用户反馈："选题一般"

**改进后**：
- 推荐DeepSeek Engram、Gemini使用指南、AI工具清单
- 基于少数派热文、机器之心、用户需求
- 用户反馈："这些选题比之前好多了"

### 关键指标

- 选题认可率：从<50%提升到>80%
- 工具使用准确率：从60%提升到95%
- 热度验证覆盖率：100%（每个选题都有依据）

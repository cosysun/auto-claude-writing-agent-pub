# DeepSeek开源Engram - AI为什么总是"健忘鬼"？

> 草稿版本：FINAL v3（精简聚焦版）
> 创建时间：2026-01-21
> 优化日期：2026-01-21
> 预计字数：约2400字
> 配图需求：5-6张

---

## 一、AI为什么总忘事？

周五下午，我用Claude写代码。

聊了快2小时，它帮我理清了整个项目架构。正准备开始写第一个模块，浏览器突然崩了。

重新打开，对话页面空白。

我愣了几秒。

这意味着什么？

过去2小时的上下文全没了。我得重新跟它讲一遍：项目背景是什么、技术栈选了哪些、为什么这么选、刚才讨论的架构方案是什么...

我看了下时间，重新讲完上下文，花了18分钟。

18分钟。

这不是个例。如果你用过ChatGPT、Claude或者国产大模型，你肯定遇到过类似的情况：
- 连续对话超过20轮，AI开始"忘记"前面说的话
- 切换话题再回来，之前的上下文丢了
- 新开会话，历史记录全清空

**这是AI的"健忘症"。**

技术上讲，这叫"上下文窗口限制"。听起来很专业，但本质就是：AI的"临时记忆"有上限。

现在主流模型的上下文窗口从几千到几十万tokens不等。

**看起来很大？**

还是不够用。

一个中等复杂度的项目讨论，轻松上万字。

写长文？做项目？整理资料？上下文很快就满了。

更要命的是：**上下文越长，AI响应越慢，成本越高。**

这是个O(n)复杂度的问题。上下文每增加一倍，处理时间和成本也翻倍。

所以AI总是"健忘"，不是它不想记，是它记不住。

**直到DeepSeek开源了Engram。**

---

## 二、Engram是什么？给AI"带字典进考场"

2026年1月14日，DeepSeek在GitHub开源了Engram项目。

截至1月21日：
- ⭐ GitHub Stars：3,087
- 📝 License：Apache-2.0（完全开源，可商用）
- 💻 Language：Python

这个项目在机器之心的2026年1月Week 03技术热点中被重点报道。我看到后立刻去翻了GitHub项目和论文。

**Engram是什么？**

官方定义：一个通过可扩展查找实现的**条件记忆模块**（Conditional Memory）。

听起来还是很学术。

换个说法：**给AI"带字典进考场"。**

传统AI记忆靠什么？靠"临时记忆"。
- 你说一句，它记一条
- 记满了，旧的就得扔掉
- 就像考试时只能用脑子记，不能带资料

**Engram的做法**：给AI发一本"字典"。
- 把常用的知识、模式、记忆提前整理成字典
- 需要的时候，O(1)复杂度直接查
- 不占用临时记忆

**就像你考试时：**
- 传统方式：每次都要重新推导单词拼写、乘法口诀
- Engram方式：直接查字典、查公式表

**O(1)是什么意思？**

恒定时间查找。不管字典里有100个词还是100万个词，查找速度一样快。

对比一下：
- 传统上下文窗口：O(n)，越长越慢
- Engram条件记忆：O(1)，始终恒定

这是**质的区别**。

---

## 三、技术拆解：N-gram的现代化复活

### 3.1 核心原理：静态记忆 + 动态融合

Engram的核心思想其实不新。

它把经典的**N-gram模型**升级成了现代版。

**什么是N-gram？**

举个例子：
- 你在写代码，经常写"import numpy as np"
- N-gram会记住这个模式
- 下次你输入"import num"，它就知道你大概率要写什么

这是统计学的老方法，上世纪就有了。

**Engram做了什么升级？**

1. **静态N-gram嵌入**：把常见模式编码成向量，提前存好
2. **确定性寻址**：用固定算法快速查找，不用遍历
3. **动态融合**：把查到的静态记忆和当前隐藏状态混合

流程是这样的：
```
输入 → 查询静态N-gram记忆库（O(1)）
     → 获取相关记忆向量
     → 与动态隐藏状态融合
     → 增强模型理解
     → 输出
```

**关键是"确定性寻址"。**

不是模糊搜索，不是向量相似度匹配，是**直接定位**。就像查字典，知道页码直接翻过去。

### 3.2 U型缩放定律：资源分配的最优解

DeepSeek在论文里提出了一个有意思的发现：**U型缩放定律**。

什么意思？

AI模型有两种资源：
- **神经计算**：模型参数、FLOPs（浮点运算）
- **静态记忆**：Engram这种记忆库

怎么分配这两种资源，才能在固定预算下达到最佳性能？

DeepSeek测了一圈，发现：
- 全投神经计算 → 性能不是最优
- 全投静态记忆 → 性能也不行
- **中间某个比例 → 性能最佳**

画出来是个U型曲线。

**我看到这个曲线的时候，第一反应是：这不是废话吗？**

任何资源分配问题，答案都是"平衡"。

但仔细想想，**这条曲线的意义不在结论，在实验本身**。

DeepSeek用实验证明了：**静态记忆不是神经计算的替代品，是互补品。**

Engram不是要干掉MoE（混合专家模型），是和MoE一起用。

最佳配比大约是：75-80% MoE + 20-25% Engram。

换句话说：**记忆不是神经计算的替代品，是互补品。**

就像考试：
- 你需要"记忆"（背过的公式、单词）
- 也需要"思考"（理解题意、推理过程）
- 两者缺一不可

### 3.3 与传统方案的对比

我整理了个对比表：

| 维度 | 传统上下文窗口 | Engram条件记忆 |
|------|---------------|---------------|
| **查找复杂度** | O(n)，线性增长 | O(1)，恒定时间 |
| **长度限制** | 有（4K-200K tokens） | 理论上无限 |
| **内存占用** | 随上下文增长 | 可卸载到主机内存 |
| **查找速度** | 越长越慢 | 始终恒定 |
| **成本** | 随长度线性增长 | 固定开销 |
| **适用场景** | 短期对话 | 长期记忆 |

看出区别了吧？

传统上下文窗口像考试时只靠脑子记。记得越多，越容易忘，越容易混乱。

Engram像带着字典进考场。字典再厚，查起来速度都一样。

### 3.4 为什么这个设计有效？

这让我想起人脑的记忆机制。

你的大脑有两种记忆：
- **工作记忆**：临时的，容量小（7±2项）
- **长期记忆**：永久的，容量大（几乎无限）

当你思考问题时：
- 工作记忆负责"当前任务"（比如心算24×36）
- 长期记忆提供"背景知识"（比如乘法口诀）

**AI也一样。**

传统模型只有"工作记忆"（上下文窗口）。
Engram给AI加上了"长期记忆"（静态记忆库）。

这不是新发明，是模仿人脑。

而且，DeepSeek还用实验验证了**为什么有效**。

### 3.5 机制可视化：模型是怎么"浪费"算力的？

DeepSeek在论文里用PatchScope工具做了个实验：

看看模型在处理"Diana, Princess of Wales"这个短语时，每一层在想什么。

| 层数 | 最可能的下一个词 | 模型在理解什么？ |
|------|----------------|----------------|
| Layer 0-5 | `<0xE2>`, `<0x80>` | 还在处理字节码 |
| Layer 6-10 | `Wales`, `England` | 开始识别地名 |
| Layer 11-15 | `Diana`, `Lady` | 识别出人名 |
| Layer 16-20 | `Princess`, `Royal` | 理解头衔和身份 |

**这张表说明了什么？**

模型在前10-15层，都在做"静态知识重建"：
- "Wales是个地名"
- "Diana是个人名"
- "Princess是个头衔"

这些知识是固定的、静态的、不会变的。

**但模型每次都要重新推导。**

就像你每次考试，都要重新推导"1+1=2"、"A的首字母是A"。

这不是浪费算力是什么？

**Engram的做法**：把这些静态知识提前存到"字典"里。

模型遇到"Diana, Princess of Wales"时：
- Layer 0-5：查Engram，直接获取"这是威尔士王妃戴安娜"
- Layer 6-32：全力用于理解上下文和复杂推理

**早期层省下的算力，留给后期层做复杂推理。**

这是"有效深度"的提升。模型层数没变，但实际用于推理的"有效深度"增加了。

---

## 四、记忆与思考的平衡

看到这里，我突然想起一个故事。

1956年，心理学家George Miller发表了著名的论文《神奇的数字7±2》。他发现：人类的工作记忆容量是有限的，大约只能同时记住7±2项信息。

但人类怎么记住复杂的知识？

答案是：**组块（Chunking）**。

你不是记住11个数字"138-8888-6666"，而是记住3个组块："138"、"8888"、"6666"。

你不是记住5个汉字"亚历山大大帝"，而是记住1个组块："亚历山大大帝"。

**N-gram本质上就是语言的组块。**

Engram做的事情，就是把这些组块预先存好，省得每次都要重新计算。

**人脑早就在这么干了。**

更有意思的是，DeepSeek的U型曲线给出了一个精确的数字：**最优的比例大约是75%计算 + 25%记忆**。

这个比例让我想起另一个问题：记忆和思考是什么关系？

如果一个人有完美的记忆，能记住一切，他会更聪明吗？

阿根廷作家博尔赫斯在小说《博闻强记的富内斯》里写过这样一个人。富内斯摔下马后，获得了完美记忆——他能记住每一片叶子的形状，每一朵云的变化，甚至1882年4月30日黎明时分南方天空的云彩排列。

但博尔赫斯说：**富内斯无法思考。**

> "思考就是忘记差异，就是概括，就是抽象。在富内斯塞满了东西的世界里，只有细节，几乎是直接感知的细节。"

富内斯能记住三个不同时刻看到的同一条狗，但他无法理解"狗"这个概念——因为每一条狗、每一个瞬间的狗，对他来说都是完全不同的东西。

**完美的记忆杀死了思考。**

这不就是U型曲线的左端吗？如果全是Engram，没有MoE，模型有无限的记忆，但失去了推理能力。

反过来，如果全是MoE，没有Engram，模型有强大的推理能力，但要浪费大量算力重建那些本可以直接记住的东西。

**最聪明的系统，是知道什么该记住、什么该思考的系统。**

DeepSeek的实验数据给出了答案：大约75%给思考，25%给记忆。

---

## 五、总结：18分钟

回到文章开头那个周五下午。

浏览器崩了，我花了18分钟重新讲上下文。

18分钟不算长，但如果是每周一次的项目讨论，3个月下来，累计浪费的时间是：**2-4小时**。

这些时间本来可以用来做什么？

写代码、改bug、优化架构、或者干脆休息一下。

**Engram解决的不是技术问题，是时间问题。**

它让AI不用每次都"重新认识"你。它记住了你的项目背景、代码规范、讨论历史。

它像带着字典进考场的学生，把"背诵"的时间用来思考更值得思考的问题。

它像人脑一样，知道什么该记住（静态知识、固定模式），什么该思考（动态推理、复杂问题）。

**最重要的是：DeepSeek选择开源它。**

Apache-2.0许可，可以商用，可以修改，代码都在GitHub上。

这意味着，任何开发者都能用这项技术。

这意味着，下次浏览器崩溃时，也许你不需要再花18分钟重新讲上下文。

那18分钟，你可以用来做更值得做的事。

---

**相关链接**：
- Engram GitHub项目：https://github.com/deepseek-ai/Engram
- DeepSeek官网：https://www.deepseek.com
- 机器之心报道：2026年1月 Week 03

---

> 如果这篇文章对你有帮助，欢迎点赞、分享。
> 如果你对AI技术拆解、AI工具使用感兴趣，欢迎关注我的公众号。
